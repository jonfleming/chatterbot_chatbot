{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.8 64-bit ('chatterbot': conda)",
   "display_name": "Python 3.7.8 64-bit ('chatterbot': conda)",
   "metadata": {
    "interpreter": {
     "hash": "392f9ab78a819428e5e50234785b42e6ec304e1cf92c043227cd608bec806c72"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;a statement&#39;]\n[]\n[(&#39;this&#39;, &#39;DET&#39;), (&#39;is&#39;, &#39;AUX&#39;), (&#39;a&#39;, &#39;DET&#39;), (&#39;statement&#39;, &#39;NOUN&#39;)]\n"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp('this is a statement')\n",
    "print([chunk.text for chunk in doc.noun_chunks])\n",
    "print([ent.text for ents in doc.ents])\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "source": [
    "doc = nlp('this is a statement')\n",
    "has_noun = 2\n",
    "has_verb = 1\n",
    "for token in doc:\n",
    "    if token.pos_ in [\"NOUN\", \"PROPN\", \"PRON\"]:\n",
    "        has_noun -= 1\n",
    "    elif token.pos_ == \"VERB\":\n",
    "        has_verb -= 1\n",
    "if has_noun < 1 and has_verb < 1:\n",
    "    print('Statement')\n",
    "else:\n",
    "    print('Not a statement')"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "doc = nlp('I live in New York')\n",
    "print([(token.text, token.pos_) for token in doc])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(&#39;I&#39;, &#39;PRON&#39;), (&#39;live&#39;, &#39;VERB&#39;), (&#39;in&#39;, &#39;ADP&#39;), (&#39;New&#39;, &#39;PROPN&#39;), (&#39;York&#39;, &#39;PROPN&#39;)]\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[live]\n"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "verb_pattern =  [{'POS': 'VERB', 'OP': '?'},\n",
    "    {'POS': 'ADV', 'OP': '*'},\n",
    "    {'POS': 'AUX', 'OP': '*'},\n",
    "    {'POS': 'VERB', 'OP': '+'},\n",
    "    {'POS': 'ADP', 'OP': '?'}]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Verbs\", None, verb_pattern)\n",
    "matches = matcher(doc)\n",
    "verbs = [doc[start:end] for _, start, end in matches]\n",
    "print([verb for verb in verbs])"
   ]
  }
 ]
}